\documentclass{article}
\usepackage[english]{babel}
\usepackage{amsmath,graphicx,theorem}

%%%%%%%%%% Start TeXmacs macros
\newcommand{\infixand}{\text{ and }}
\newcommand{\tmaffiliation}[1]{\\ #1}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmxspace}{\hspace{1em}}
{\theorembodyfont{\rmfamily}\newtheorem{answer}{Answer}}
%%%%%%%%%% End TeXmacs macros

\begin{document}

{\screens{\

\title{MAE5003 Homework5}

\author{
  Zitong Huang
  \tmaffiliation{12432670@mail.sustech.edu.cn}
}

\maketitle

\section*{Question 1}

\begin{answer}
  \ 
\end{answer}

Let
\begin{equation}
  X_k = x_k - \bar{x}
\end{equation}
\begin{equation}
  Y_k = y_k - \overline{y}
\end{equation}
Consider original loss function $E (A, B)$, we have
\[ E (A, B) = \overset{N}{\underset{k = 1}{\sum}} (y_k - (Ax_k + B))^2 \]


Let (1)(2) in, we have
\[ E (A, B) = \overset{N}{\underset{k = 1}{\sum}} (\bar{y} + Y_k - (A \bar{x}
   + AX_k + B)) \]
From normal equations, we have $\bar{y} - (A \bar{x} + B) = 0$

Thus $E (A, B) = \overset{N}{\underset{k = 1}{\sum}} (Y_k - A X_k)^2$

Let the loss function $E (A) = \overset{N}{\underset{k = 1}{\sum}} (Y_k - A
X_k)^2$

Take the partial derivative with respect to $A$, we have


\begin{equation}
  \frac{\partial E}{\partial A} = \underset{k = 1}{\overset{N}{\sum}} 2 (Y_k -
  A X_k) (- X_k)
\end{equation}
Let $\frac{\partial E}{\partial A} = 0$, solve $A$, we have
\begin{equation}
  A = \frac{\overset{N}{\underset{k = 1}{\sum}} X_k
  Y_k}{\overset{N}{\underset{k = 1}{\sum}} X^2_k}
\end{equation}
Let (1) and (2) in, \ we have
\[ A = \frac{\sum_{k = 1}^N (y_k - \bar{y}) (x_k - \bar{x})}{\sum_{k = 1}^N
   (x_k - \bar{x})^2} = \frac{1}{C} \sum_{k = 1}^N (y_k - \bar{y}) (x_k -
   \bar{x}) \]
where $C = \sum_{k = 1}^N (x_k - \bar{x})^2$

\section*{Question 2}

\begin{answer}
  \ 
\end{answer}

\subsection*{(a)}

\begin{eqnarray*}
  E (A) = \frac{1}{2} \overset{N}{\underset{k = 1}{\sum}} (y_k - A x_k)^2 &  &
  \\
  \frac{\partial E}{\partial A} = \underset{k = 1}{\overset{N}{\sum}} 2 (y_k -
  A x_k) (- x_k) &  & 
\end{eqnarray*}
Let $\frac{\partial E}{\partial A} = 0$, solve $A$, we have
\begin{equation}
  \overset{N}{\underset{k = 1}{\sum}} Ax^2_k - \overset{N}{\underset{k =
  1}{\sum}} x_k y_k = 0
\end{equation}
So the normal function is
\[ A = \frac{\overset{N}{\underset{k = 1}{\sum}} x_k
   y_k}{\overset{N}{\underset{k = 1}{\sum}} x^2_k} \]

\subsection*{(b)}

\begin{eqnarray*}
  E (A) = \frac{1}{2} \overset{N}{\underset{k = 1}{\sum}} (y_k - A x^3_k)^2 & 
  & \\
  \frac{\partial E}{\partial A} = \underset{k = 1}{\overset{N}{\sum}} (y_k - A
  x^3_k) (- x^3_k) &  & 
\end{eqnarray*}
Let $\frac{\partial E}{\partial A} = 0$, solve $A$, we have
\begin{equation}
  \overset{N}{\underset{k = 1}{\sum}} Ax^6_k - \overset{N}{\underset{k =
  1}{\sum}} x^3_k y_k = 0
\end{equation}
So the normal function is
\[ A = \frac{\overset{N}{\underset{k = 1}{\sum}} x^3_k
   y_k}{\overset{N}{\underset{k = 1}{\sum}} x^6_k} \]


\subsection*{(c)}

Loss function is
\[ E (A, B) = \underset{k = 1}{\overset{N}{\sum}} (y_k - (Ax_k^3 + B)) \]
Get the partial derivative, we have
\[ \  \]
\begin{eqnarray*}
  \frac{\partial E}{\partial A} = - 2 \sum_{k = 1}^n x_k^3  (y_k - Ax_k^3 - B)
  = 0 &  & \\
  \frac{\partial S}{\partial B} = - 2 \sum_{i = 1}^n (y_i - Ax_i^3 - B) = 0 & 
  & 
\end{eqnarray*}
Solve, we have
\[ \left\{\begin{array}{l}
     A \sum_{i = 1}^n x_i^6 + B \sum_{i = 1}^n x_i^3 = \sum_{i = 1}^n x_i^3
     y_i\\
     A \sum_{i = 1}^n x_i^3 + Bn = \sum_{i = 1}^n y_i
   \end{array}\right. \]


\section*{Question 3}

\begin{answer}
  \ 
\end{answer}

\textbf{For function 1}, arranged to get
\[ \ln y = Ax + \ln C \Rightarrow Y = AX + B \]
where
\begin{equation}
  Y = \ln y, X = x, B = \ln C
\end{equation}
Error function $E (A, B)$ equals to
\[ E (A, B) = \overset{N}{\underset{i = 1}{\sum}} (Y_i - (AX_i + B))^2 \]
Let $\frac{\partial E}{\partial A} = 0$, we have
\begin{eqnarray}
  \underset{i = 1}{\overset{N}{\sum}} (X_i Y_i - AX_i^2 - 2 BX_i) = 0 &  & 
  \nonumber\\
  \Rightarrow A \sum_{i = 1}^n X_i^2 + B \sum_{i = 1}^n X_i = \sum_{i = 1}^n
  X_i Y_i &  & 
\end{eqnarray}
Let $\frac{\partial E}{\partial B} = 0$, we have
\begin{eqnarray*}
  \underset{i = 1}{\overset{N}{\sum}} (Y_i - AX_i - B) = 0 &  & \\
  \Rightarrow A \sum_{i = 1}^n X_i + Bn = \sum_{i = 1}^n Y_i &  & 
\end{eqnarray*}
Thus the Normal equations is
\[ \left\{\begin{array}{l}
     A \sum_{i = 1}^n X_i^2 + B \sum_{i = 1}^n X_i = \sum_{i = 1}^n X_i Y_i\\
     A \sum_{i = 1}^n X_i + Bn = \sum_{i = 1}^n Y_i
   \end{array}\right. \]
Let data point $A : (x_k, y_k) = \{(1, 0.6), (2, 1.9), (3, 4.3), (4, 7.6), (5,
12.6)\}$ and equation (7) in, we can solve


\[ \left\{\begin{array}{l}
     A = 0.747\\
     C = 0.363
   \end{array}\right. \]
The final loss is
\[ E = \overset{N}{\underset{i = 1}{\sum}} (Y_i - (AX_i + B))^2  \text{, \
   Point set $A$} \]
Solve to get $E = 8.102$

\

\textbf{For function 2}, arranged to get
\[ \ln y = A \ln x + \ln \rightarrow Y = AX + B \]
where
\[ Y = \ln y, \quad X = \ln x, \quad B = \ln C \]
Error function $E (A, B)$ equals to
\[ E (A, B) = \sum_{i = 1}^N (Y_i - (AX_i + B))^2 \]
Let $\frac{\partial E}{\partial A} = 0$, we have
\[ \sum_{i = 1}^N X_i Y_i - A \sum_{i = 1}^N X_i^2 - B \sum_{i = 1}^N X_i = 0
\]
\[ \Rightarrow A \sum X_i^2 + B \sum X_i = \sum X_i Y_i \]
Let $\frac{\partial E}{\partial B}$, we have
\[ \sum_{i = 1}^N Y_i - A \sum_{i = 1}^N X_i - BN = 0 \]
\[ \Rightarrow A \sum X_i + BN = \sum Y_i \]
Thus the Normal equations are
\[ \left\{\begin{array}{l}
     A \sum_{i = 1}^n X_i^2 + B \sum_{i = 1}^n X_i = \sum_{i = 1}^n X_i Y_i\\
     A \sum_{i = 1}^n X_i + Bn = \sum_{i = 1}^n Y_i
   \end{array}\right. \]


Let data point
\[ A : (x_k, y_k) = \{(1, 0.6), (2, 1.9), (3, 4.3), (4, 7.6), (5, 12.6)\} \]
and apply transformation $X_i = \ln x_i, \hspace{0.27em} Y_i = \ln y_i$ into
equation (8), we solve
\[ \left\{\begin{array}{l}
     A = 1.886\\
     C = 0.562
   \end{array}\right. \]
The final loss is 0.8725938171171367.

Thus , we can have function 2 is better.

\

\section*{Data B}

Same as Data A,

Let data points B in, we can calculate for $f (x) = C e^{A x}$, $A$ and $C$
is
\[ \left\{\begin{array}{l}
     A = - 0.508\\
     C = 3.866
   \end{array}\right. \]
The final loss $E = 0.07$

\

For function $f (x) = \frac{1}{A x + B}$, we can calculate for $\frac{1}{g
(x)} = A x + B$, where $g (x) = \frac{1}{f (x)}$, which $A$ and $C$ be
\[ \left\{\begin{array}{l}
     A = 0.24\\
     B = 0.30
   \end{array}\right. \]
The final loss $E = 103$.

\

\section*{Question 4}

Let the loss equation be
\[ E (A, B, C) = \sum_{k = 1}^N (A x_k + B y_k + C - z_k)^2 \]
We can have
\[ \frac{\partial E}{\partial A} = \sum_{k = 1}^N 2 (A x_k + B y_k + C - z_k)
   \tmxspace (x_k) \]
\[ \frac{\partial E}{\partial B} = \sum_{k = 1}^N 2 (A x_k + B y_k + C - z_k)
   \tmxspace (y_k) \]
\[ \frac{\partial E}{\partial C} = \sum_{k = 1}^N 2 (A x_k + B y_k + C - z_k)
   \tmxspace \]
Let $\frac{\partial E}{\partial A}, \frac{\partial E}{\partial B},
\frac{\partial E}{\partial C}$ be 0, we have equations
\[ \sum_{k = 1}^N (A x^2_k + B x_k y_k + C x_k - x_k z_k) = 0 \]
\[ \sum_{k = 1}^N (A x_k y_k + B y_k^2 + C y_k - y_k z_k) = 0 \]
\[ A x_k + B y_k + C - z_k \tmxspace = 0 \]
Which is equals to
\[ A \sum_{k = 1}^N x^2_k + B \sum_{k = 1}^N x_k y_k + C \sum_{k = 1}^N x_k -
   \sum_{k = 1}^N x_k z_k = 0 \]
\[ A \sum_{k = 1}^N x_k y_k + B \sum_{k = 1}^N y_k^2 + C \sum_{k = 1}^N y_k -
   \sum_{k = 1}^N y_k z_k = 0 \]
\[ A \sum_{k = 1}^N x_k + B \sum_{k = 1}^N y_k + C - \sum_{k = 1}^N z_k
   \tmxspace = 0 \]
Equals to the given functions.

\

\section*{Question 5}

Given the second derivative formulation:
\[ \frac{h_{i - 1}}{6} M_{i - 1} + \frac{h_{i - 1} + h_i}{3} M_i +
   \frac{h_i}{6} M_{i + 1} = \frac{y_{i + 1} - y_i}{h_i} - \frac{y_i - y_{i -
   1}}{h_{i - 1}} \]
where $h_{i - 1} = x_i - x_{i - 1}, h_i = x_{i + 1} - x_i$

and equation to calculate $S_i (x)$:
\begin{equation}
  S_i (x) = \frac{M_{i + 1}}{6 h_i}  (x - x_i)^3 + \frac{M_i}{6 h_i}  (x_{i +
  1} - x)^3 + \left( \frac{y_{i + 1}}{h_i} - \frac{M_{i + 1} h_i}{6} \right) 
  (x - x_i) + \left( \frac{y_i}{h_i} - \frac{M_i h_i}{6} \right)  (x_{i + 1} -
  x)
\end{equation}
and four points:
\[ A_0 = (- 3, 2), A_1 = (- 2, 0), A_2 = (1, 3), A_3 = (4, 1) \]
Let $i = 1$,we have
\[ \frac{1}{6} M_{i - 1} + \frac{4}{3} M_i + \frac{3}{6} M_{i + 1} =
   \frac{3}{3} - \frac{- 2}{1} \]
Let $i = 2$, we have
\[ \frac{3}{6} M_{i - 1} + \frac{6}{3} M_i + \frac{3}{6} M_{i + 1} = \frac{-
   2}{3} - \frac{3}{3} \]
Simplify, we have
\[ \frac{4 M_1}{3} + \frac{M_2}{2} + \frac{M_0}{6} = 3 \]
\[ 2 M_2 + \frac{M_3}{2} + \frac{M_1}{2} = - \frac{5}{3} \]
Also, we have $M_0 = 0$, $M_3 = 0$. Solve the linear equation, we have
\[ \left\{\begin{array}{l}
     M_1 = 2.83\\
     M_2 = - 1.54
   \end{array}\right. \]


Let $M_0, M_1, M_2, M_3$ in to equation (9), we have
\[ \
   
   \subsection*{\tmop{Segment} 1 : S_0 (x), \tmop{interval} [- 3, - 2]}
   
   \[ S_0 (x) = 2 - 2.471264 (x + 3) + 0.471264 (x + 3)^3 \]
   
   \subsection*{\tmop{Segment} 2 : S_1 (x), \tmop{interval} [- 2, 1]}
   
   \[ S_1 (x) = - 1.057471 (x + 2) + 1.413793 (x + 2)^2 - 0.242656 (x + 2)^3
   \]
   
   \subsection*{\tmop{Segment} 3 : S_2 (x), \tmop{interval} [1, 4]}
   
   \[ S_2 (x) = 3 + 0.873563 (x - 1) - 0.770115 (x - 1)^2 + 0.085568 (x - 1)^3
   \] \]


\section*{Question 6}

Derivate the interval into

- $[- 3, - 2) :$
\[ S_1 (x) = a_1 + b_1  (x + 3) + c_1  (x + 3)^2 + d_1  (x + 3)^3 \]
- $[- 2, 1) :$
\[ S_2 (x) = a_2 + b_2  (x + 2) + c_2  (x + 2)^2 + d_2  (x + 2)^3 \]
- $[1, 4) :$
\[ S_3 (x) = a_3 + b_3  (x - 1) + c_3  (x - 1)^2 + d_3  (x - 1)^3 \]
From the limitation of function value, we have
\begin{equation}
  \left\{\begin{array}{l}
    S_1 (- 3) = 2\\
    S_1 (- 2) = S_2 (- 2) = 0\\
    S_2 (1) = S_3 (1) = 3\\
    S_3 (4) = 1
  \end{array}\right.
\end{equation}
From the derivation limitation, we have
\begin{equation}
  \left\{\begin{array}{l}
    S_1' (- 2) = S_2' (- 2)\\
    \\
    S_2' (1) = S_3' (1)
  \end{array}\right.
\end{equation}


From the second derivation limitation, we have
\begin{equation}
  \left\{\begin{array}{l}
    S_1''  (- 2) = S_2''  (- 2)\\
    \\
    S_2'' (1) = S_3'' (1)
  \end{array}\right.
\end{equation}
From the Parabolic Termination, we have
\begin{equation}
  \left\{\begin{array}{l}
    S_1''  (- 3) = S_2''  (- 2)\\
    \\
    S_2'' (1) = S_3'' (4)
  \end{array}\right.
\end{equation}
Solve the equation (10)(11)(12)(13), we have
\[ S_1 (x) = 2 - \frac{67}{21}  (x + 3) + \frac{25}{21}  (x + 3)^2 \]
\[ S_2 (x) = - \frac{17}{21}  (x + 2) + \frac{25}{21}  (x + 2)^2 -
   \frac{37}{189}  (x + 2)^3 \]
\[ S_3 (x) = 3 + \frac{22}{21}  (x - 1) - \frac{4}{7}  (x - 1)^2 \]

\section*{Question 7}

(a) The derivation of $f (x)$ is
\[ f' (x) = 6 x^2 - 1 \]
Thus
\[ f'  (- 2) = 6 (- 2)^2 - 1 = 24 - 1 = 23 \]
\[ f' (0) = - 1 \]
So it is a Clamped Cubic Spline in $[- 2, 0]$

\

(b) For Function Continuity we have
\[ f' (x) = 3 x^2 - 1 \]
\[ f'' (x) = 6 x \]
For $x = 0$ we have
\[ f' (0^-) = f' (0^+) = - 1 \]
\[ f'' (0^-) = f'' (0^+) = 0 \]
For function bounds data we have
\[ f'  (- 2) = 3 \cdot 4 - 1 = 11 \]
\[ f' (2) = 3 \cdot 4 - 1 = 11 \]
So it is a Clamped Cubic Spline in $[- 2, 2]$

\

(c)

Let $f (x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3$ be any third-degree polynomial
defined on a closed interval $[a, b]$.

A clamped cubic spline $S (x)$ on $[a, b]$ satisfies the following
properties:
\begin{enumerate}
  \item $S (x)$ is a piecewise cubic polynomial defined on subintervals of
  $[a, b]$,
  
  \item $S (x)$, $S' (x)$, and $S'' (x)$ are continuous on $[a, b]$,
  
  \item The first derivatives at the endpoints satisfy the clamped (also known
  as Hermite) boundary conditions:
  \begin{equation}
    S' (a) = f' (a), S' (b) = f' (b)
  \end{equation}
  .
\end{enumerate}
In this case, since $f (x)$ is already a single cubic polynomial, it is
trivially a cubic spline over any subinterval partition of $[a, b]$, with no
need for piecewise definitions. Additionally, all derivatives of $f (x)$ are
continuous everywhere, and particularly on $[a, b]$.

Moreover, because $S (x) = f (x)$, the endpoint derivatives of the spline
naturally satisfy equation (14)

which meets the clamped boundary conditions.

Therefore, all requirements of a clamped cubic spline are satisfied by f(x)
itself.

\

\section*{Question 8}

For $a_0$, we have
\[ a_0 = \frac{1}{P}  \int_{- 3}^3 f (x)  \hspace{0.17em} dx = \frac{1}{3} 
   \left[ \int_{- 3}^{- 1} (- 1) \hspace{0.17em} dx + \int_{- 1}^1 x
   \hspace{0.17em} dx + \int_1^3 1 \hspace{0.17em} dx \right] \Rightarrow a_0
   = 0 \]
For $a_j$, we have
\[ a_j = \frac{1}{3}  \left[ \int_{- 3}^{- 1} (- 1) \cos \left( \frac{j \pi
   x}{3} \right) dx + \int_{- 1}^1 x \cos \left( \frac{j \pi x}{3} \right) dx
   + \int_1^3 1 \cos \left( \frac{j \pi x}{3} \right) dx \right] \]
For $b_j$, we have
\[ b_j = \frac{1}{3}  \left[ \int_{- 3}^{- 1} (- 1) \sin \left( \frac{j \pi
   x}{3} \right) dx + \int_{- 1}^1 x \sin \left( \frac{j \pi x}{3} \right) dx
   + \int_1^3 1 \sin \left( \frac{j \pi x}{3} \right) dx \right] \]
Solve, we have
\[ {a_j}  = 0 \]
and for $b_j$, we have
\[ \\
   b_1 \approx 1.6310
   
   b_2 \approx - 0.18669
   
   b_3 \approx 0.21221
   
   b_4 \approx - 0.19206
   
   b_5 \approx 0.10626
   
   b_6 \approx - 0.10610 \]
The graph of $S_4 \infixand S_6$ is

\raisebox{0.0\height}{\includegraphics[width=8.428669815033452cm,height=5.282631509904237cm]{question8.png}}

\section*{Question 9}
(a) $P{\prime}{\prime}(0)$

Let us express the interpolating polynomial using the Lagrange form:

$P(x) = \sum_{i=0}^{N} P_i \cdot \ell_i(x)$,
where $\ell_i(x)$ is the Lagrange basis polynomial defined by:
\[
\ell_i(x) = \prod_{\substack{j = 0 \\ j \ne i}}^{N} \frac{x - x_j}{x_i - x_j}.
\]

Taking the second derivative:
$$
P{\prime}{\prime}(x) = \sum_{i=0}^{N} P_i \cdot \ell_i{\prime}{\prime}(x)
$$.

To evaluate $P{\prime}{\prime}(0)$, we compute:
$$P{\prime}{\prime}(0) = \sum_{i=0}^{N} P_i \cdot \ell_i{\prime}{\prime}(0)$$.

In the case of equally spaced nodes $x_i = \frac{i}{N}$, it is known that:
$$\ell_0{\prime}{\prime}(0) = N(N-1), \quad \ell_1{\prime}{\prime}(0) = -2N(N-1), \quad \ell_2{\prime}{\prime}(0) = N(N-1)$$,
and $$\ell_i{\prime}{\prime}(0) = 0 for i \geq 3$$.

Thus,
$$P{\prime}{\prime}(0) = P_0 \cdot N(N-1) + P_1 \cdot (-2N(N-1)) + P_2 \cdot N(N-1)$$,
$$P{\prime}{\prime}(0) = N(N-1)(P_2 - 2P_1 + P_0)$$.

(b) $P{\prime}{\prime}(1)$

Similarly, we compute:
$$P{\prime}{\prime}(1) = \sum_{i=0}^{N} P_i \cdot \ell_i{\prime}{\prime}(1)$$.

In the case of equally spaced nodes, we have:
$$\ell_N{\prime}{\prime}(1) = N(N-1), \quad \ell_{N-1}{\prime}{\prime}(1) = -2N(N-1), \quad \ell_{N-2}{\prime}{\prime}(1) = N(N-1)$$,
and $$\ell_i{\prime}{\prime}(1) = 0 \textbf{ for } i \leq N-3$$.

Thus, we have
$$P{\prime}{\prime}(1) = P_N \cdot N(N-1) + P_{N-1} \cdot (-2N(N-1)) + P_{N-2} \cdot N(N-1)$$,
$$P{\prime}{\prime}(1) = N(N-1)(P_N - 2P_{N-1} + P_{N-2})$$.

\ }{}{}}

\end{document}
s